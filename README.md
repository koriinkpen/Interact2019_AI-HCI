## Overview

* [Motivation](#motivation)
* [Call for Participation](#call-for-participation)
* [Objectives and Target Audience](#objectives-and-target-audience)
* [Themes](#themes)
* [Organisers](#organisers)
* [Schedule](#schedule)
* [Expected Outcomes](#expected-outcomes)
* [References](#references)

## Motivation

As more and more artificial intelligent systems become incorporated into our every-day lives, it is critical that we understand the ways in which people will interact with these systems. Although some AI systems will be fully automated, a large number will be incorporated into a larger social ecosystem where people will be interacting with these systems.  In some cases, advances in machine learning are enabling systems to make inferences on data that are more precise than human experts, however, there is also a growing body of literature that shows that these systems have inherent bias and can have a negative impact on human decision making [3]. It is imperative that researchers understand the smart interplay of AI systems and human experts such that the combination of the two can leverage the inherent strength and weaknesses of each to lead to optimal results. In this workshop, we seek to bring together researchers from both Artificial Intelligence and Human-Computer Interaction communities to discuss concepts, systems, designs, and empirical studies focusing on the communica-tion and cooperation between individual users and teams of users with AI systems.

## Call for Participation

**We invite submissions for a one-day workshop to discuss critical questions in bringing the human into the development and deployment of artificial intelligence (AI) systems.**

Papers should be **2-4 pages long** in the [XXX](https://chi2019.acm.org/authors/chi-proceedings-format/) format, and may address any topics related to the intersections of HCI, AI, and machine learning. This includes but is not limited to ongoing work; reflections on past work; combining methods from HCI and design to AI; and emergent ethical, political, and social challenges. 

The **due date for submissions is no later than XXX, 2019**  (*submission method to be confirmed*). Participants will be selected based on the quality and clarity of their submissions as they reflect the interests of the workshop. Notifications will go out no later than March 1, 2019. At least one author of each accepted position paper must attend the workshop, and all participants must register for both the workshop and at least one day of the conference.

Participants will be selected based on their prior experience and interest in the workshop as well as the quality of their submissions. We will focus on recruiting from a diverse group of participants, with a balance of students and faculty; industry practitioners and academic audiences; contribution areas within HCI and AI research; and representation of different cultures, genders, and ethnic backgrounds.

Selection of participants and presentations will be based on refereed submissions. We invite authors to submit 4-page papers reporting their contributions in the field of the workshop or 2-page position statements motivating their interest in specific workshop topics. Papers should be formatted according to the INTERACT 2019 (Springer LNCS Series) format. An expert panel of 3-4 researchers will be recruited to review the submissions and participate in the conference.
Authors of accepted submissions as well as invited researchers will give short presentations. We will interweave presentation sessions with longer periods of discus-sions. Presentations will be grouped by key topics to foster spontaneous discussions. If participants are interested, archival publication opportunities will be discussed, in addition to follow-on workshops. 


## Objectives and Target Audience

The goal of this workshop is to bring together researchers from diverse communities such as Human-Computer Interaction, Machine Learning, Computer-Supported Cooperative Work, Interaction Design, Group Decision Support Systems, Visualisa-tion, Philosophy and Ethics. This workshop will build on the insights gained from a larger workshop we are organising at CHI 2019 (http://aka.ms/whereisthehuman), but focus in more specifically in issues related to Human+AI interaction.  
The structure of this workshop will be focused on creating research partnerships and identifying collaborative projects.  Although we will spend time discussing key trends, challenges, and opportunities, the overall goal is to have a focused workshop that will initiate projects that will extend beyond the workshop itself. The intimate nature of workshops at INTERACT is an ideal venue for this type of workshop. 


## Themes
=====================================

This workshop will focus on three sub-themes related to Human + AI Collaboration: 

1.  **Integrating Artificial and Human Intelligence**: AI systems and humans both have unique abilities and are typically better at certain complementary tasks than others. For instance, while AI systems can summarize voluminous data to identify latent patterns, humans can ex-tract meaningful, relatable, and theoretically grounded insights from such patterns. What kind of research designs or problems are most amenable to and would benefit the most from combining artificial and human intelli-gence? What challenges might surface in attempting to do so? How do issues of trust and accountability impact results \[5, 7\]?

2.  **Collaborative Decision Making:** How can we harness the best of humans and algorithms to make better de-cisions than either alone? How do we ensure that when there is a human-in-the-loop—such as in complex or life-changing decision-making—they re-main critical and meaningful, while creating and maintaining an enjoyable user experience? Where is the line between decision support anticipating the needs of the user and it removing the user’s ability to bring in novel, qualita-tive critical knowledge to enable the system’s goals?

3.  **Explainable and Explorable AI**: What does the human need to effectively utilize AI insights? How can users explore AI systems’ results and logic to identify failure modes that might not be easy to spot? Examples might be undesirable impacts on latent groups not corresponding to categories in the dataset \[6\], difficult-to-spot changes (‘concept drift’), or feedback loops in the socio-technical phenomena the AI system is modelling over time \[2\].


## Organisers
==========

**[Dr. Tom Gross](http://www.tomgross.net/)** is full professor and chair of Human-Computer Interaction at the Faculty of Infor-mation Systems and Applied Computer Science of the University of Bamberg, Ger-many. His research interests are particularly in the fields of Computer-Supported Cooperative Work, Human-Computer Interaction, and Ubiquitous Computing. He has participated in and coordinated activities in various national and international research projects and is a member of the IFIP Technical Committee on ‘Human Computer Interaction’ (TC.13). He has been conference co-chair and organiser of many international conferences. 

**[Dr. Kori Inkpen](https://www.microsoft.com/en-us/research/people/kori/)** is a Principal Researcher at Microsoft, where she is a member of the Microsoft Re-search AI team. Dr. Inkpen’s research interests are focused on Human+AI Collabora-tion to enhance decision making, particularly in high-impact social contexts which inevitably delves into issues of Bias and Fairness. Kori has been a core member of the CHI community for over 20 years. Prior to joining Microsoft she was a Professor of Computer Science at Dalhousie University and Simon Fraser University. 

**[Dr. Brian Y. Lim](http://brianlim.net/)** is an assistant professor in the Department of Computer Science at the National Uni-versity of Singapore. He is leading the NUS Ubicomp Lab, where he and his team design, develop, and evaluate needs-driven infocomm technologies to address new societal challenges, such as urban systems, sustainability and energy management, healthcare and well-being. He has conducted research in intelligent systems across multiple modalities (IoT sensors, mobile interfaces, web and dashboards) and multi-ple scales (smartphones, smart homes, and smart cities). This allows me to develop impactful technological solutions for multiple domains, and to translate these inno-vations from the lab to society. 

**[Michael Veale](https://michae.lv)** is a doctoral researcher in responsible public sector machine learning at the Dept. of Science, Technology, Engineering & Public Policy at University College London. His work spans HCI, law and policy, looking at how societal and legal concerns around machine learning are understood and coped with on the ground.


## Schedule

The (proposed) schedule includes:

0900 - Welcome and Introduction
0915 – Lightning Talks by workshop participants
1015 - Mid-morning break
1030 – Full-group brainstorming of possibly project areas
1200 - Lunch break
1300 - Breakout Groups
1430 - Mid-afternoon break
1500 - Report back from Breakout Groups
1600 - Brainstorm next steps
1700 - Workshop concludes


## Expected Outcomes

Three key outcomes are expected from this workshop. First, community building and networking among key researchers in the area of Human+AI collaboration, with the potential to lead to future collaborations on projects or larger grant proposals.  Sec-ond, an outline of important research directions for this emerging area. Third, one or more research projects that will continue beyond the workshop, the results of which will be published in premiere research venues.

## References

1\.	Amershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B., Collisson, P., Shu, J., Iq-bal, S., Bennett, P.N., Inkpen, K., Teevan, J., Kikin-Gil, R. and Horvitz, E. *Guidelines for Human-AI Interaction*. In Proceedings of the Conference on Human Factors in Computing Systems - CHI 2019 (May 4-9, Glasgow, Scotland). ACM, N.Y., (to appear). 

2\.	Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M., and Bouchachia, A. *A survey on concept drift adaptation*. ACM Computing Surveys 1, 1. https://doi.org/10.1145/2523813

3\.	Green, B., and Chen, Y. *Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments*. In Proceedings of the ACM Conference on Fairness, Ac-countability, and Transparency - FAT* 2019 (January 29-31, Atlanta, GA). ACM N.Y.  

4\.	Gross, T. *Supporting Informed Negotiation Processes in Group Recommender Systems*. i-com - Journal of Interactive Media 14, 1 (Jan. 2015). pp. 53-61. 

5\.	Saxena, N.A., Huang, K., DeFilippis, E., Radanovic, G., Parkes, D.C., Liu, Y. *How Do Fairness Deﬁnitions Fare? Examining Public Attitudes Towards Algorithmic Deﬁnitions of Fairness*. In Proceedings of Association for the Advancement of Artificial Intelligence – AAAI 2019. 

6\.	Veale M. and Binns, R. *Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data*. Big Data & Society 4, 2. https://doi.org/10/gdcfnz

7\.	Yin, M., Wortman Vaughan, J., Wallach, H., *Understanding the Effect of Accuracy on Trust in Machine Learning Models*. In Proceedings of the Conference on Human Factors in Com-puting Systems - CHI 2019 (May 4-9, Glasgow, Scotland). ACM, N.Y., (to appear).

88\. Eric P. S. Baumer. 2017. Toward Human-Centered Algorithm Design. *Big Data & Society* 4, 2. <https://doi.org/10.1177/2053951717718854>
89\. Munmun De Choudhury and Emre Kiciman. 2018. Integrating artificial and human intelligence in complex, sensitive problem domains: Experiences from mental health. *AI Magazine* 39, 3.

90\. Alexandra Olteanu, Carlos Castillo, Fernando Diaz, and Emre Kiciman. 2016. Social data: Biases, methodological pitfalls, and ethical boundaries.

91\. Michael Veale, Max Van Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in high-stakes public sector decision-making. In *CHI'18*. <https://doi.org/10/ct4s>



